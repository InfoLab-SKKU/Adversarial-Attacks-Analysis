{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQF8-Op4LPRT"
   },
   "source": [
    "## <font color='purple'> **Testing CIFAR-10 trained models** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xqkNEMlQAmQ5"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UtOOb8GiRPvF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tuJ2TQYn9lDr"
   },
   "outputs": [],
   "source": [
    "### import archetecture of models \n",
    "\n",
    "from models.vgg_models import * \n",
    "\n",
    "## you can test followings as well: \n",
    "# from models.resnet_models import * \n",
    "# from models.densenet_models import * \n",
    "# from models.mobilenet_models import * \n",
    "# from models.mobilenetV2_models import * \n",
    "# from models.googlenet_models import *  \n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xdsd0axWP284"
   },
   "outputs": [],
   "source": [
    "## getting the archetecture of model from models.vgg_models \n",
    "vgg19_model = VGG('VGG19')\n",
    "\n",
    "## you can test followings as well:  \n",
    "# vgg11_model = VGG('VGG11')\n",
    "# vgg16_model = VGG('VGG16')\n",
    "# resnet18_model = ResNet18()\n",
    "# resnet50_model = ResNet50() \n",
    "# densenet121_model = DenseNet121() \n",
    "# mobilenet_model = MobileNet()\n",
    "# mobilenetV2_model = MobileNetV2() \n",
    "# googlenet_model = GoogleNet() \n",
    "# ... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qp9QuNwhWGsi",
    "outputId": "11555a2f-f38c-4583-b43d-611aaf043440"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (53): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## layers of model \n",
    "vgg19_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHDw5JdfP9nX",
    "outputId": "24eef3e4-5f04-4268-d684-ab4b306b92b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is loadded!\n"
     ]
    }
   ],
   "source": [
    "## your directory of trained models  \n",
    "trained_models_directory = \"gdrive/MyDrive/models/\" \n",
    "model_file_name = \"vgg19_cifar10.pth\" \n",
    "device_name = 'cuda:0'\n",
    "\n",
    "path = os.path.join(trained_models_directory, model_file_name) \n",
    "\n",
    "## load the model \n",
    "## map location, we trained models in different GPU (e.g. cuda:1, cuda:2), for that reason you should map your gpu before using  \n",
    "vgg19_model.load_state_dict(torch.load(path, map_location=device_name)['net'])\n",
    "\n",
    "## model in evaluation mode \n",
    "vgg19_model.eval()\n",
    "\n",
    "## state of the models are saved as follow: \n",
    "# state = {\n",
    "#          'net': net.state_dict(),\n",
    "#          'acc': acc,\n",
    "#          'epoch': epoch,\n",
    "#         }\n",
    "\n",
    "print (\"Model is loadded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kKZoX7HaQCPA",
    "outputId": "ded6ed49-f3b9-4236-af31-ab65149f6cdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## you can get accuracy of the model on test \n",
    "torch.load(path, map_location='cuda:0')['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cE5hnMaQA-X7"
   },
   "source": [
    "### <font color='green'> ***Testing the model*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nOrKaxT1_qtJ"
   },
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rQnG06gOAFmZ"
   },
   "outputs": [],
   "source": [
    "### loading test image\n",
    "image_dir = 'example_images' \n",
    "image_name = 'airplane_ex1.png'\n",
    "\n",
    "image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "input_image = Image.open(image_path) \n",
    "input_tensor = transform_test(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "fsfx8IMZCx5M",
    "outputId": "95745afb-e443-4f2d-a4c0-fd5843347aec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54d4e3c510>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### printing image \n",
    "input = input_batch[0].numpy().astype(np.float32).transpose((1,2,0))\n",
    "\n",
    "plt.imshow(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2mTPvYRGE9UP"
   },
   "outputs": [],
   "source": [
    "## Softmax for getting probability \n",
    "\n",
    "def softmax_activation(inputs): \n",
    "  inputs = inputs.tolist()\n",
    "  exp_values = np.exp(inputs - np.max(inputs)) \n",
    "  # Normalize \n",
    "  probabilities = exp_values / np.sum(exp_values)\n",
    "\n",
    "  return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VNFlCx9A5G5",
    "outputId": "6c9aa5eb-0bfd-4ebc-de9a-dec06f9d3008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: [0], confidence: 100.0%\n"
     ]
    }
   ],
   "source": [
    "predection = vgg19_model(input_batch)\n",
    "\n",
    "probability = np.max(softmax_activation(predection), axis=1)[0]\n",
    "probability = round(probability*100, 2) \n",
    "\n",
    "label = np.argmax(predection.detach().numpy(), axis=1) \n",
    "\n",
    "print(\"Predicted label: {}, confidence: {}%\".format(label, probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ2yFesJKVub"
   },
   "source": [
    "#### Labels \n",
    "\n",
    "* Airplane: [0]\n",
    "* Automobile: [1] \n",
    "* Bird:       [2] \n",
    "* Cat:        [3]\n",
    "* Deer: [4]\n",
    "* Dog: [5] \n",
    "* Frog: [6]\n",
    "* Horse: [7] \n",
    "* Ship: [8]\n",
    "* Truck [9]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_cifar10_trained_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
