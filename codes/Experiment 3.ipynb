{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Box Attacks and Defenses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datetime import datetime ## important \n",
    "import time \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_codes_cifar10.vgg_cifar10 import * \n",
    "from model_codes_cifar10.resnet_cifar10 import * \n",
    "from model_codes_cifar10.densenet_cifar10 import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device_name = 'cuda:1'\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attacks from ART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import NewtonFool \n",
    "from art.attacks.evasion import CarliniL2Method\n",
    "from art.attacks.evasion import SimBA\n",
    "from art.attacks.evasion import HopSkipJump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some methods and variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_activation(inputs): \n",
    "    inputs = inputs.tolist()\n",
    "    exp_values = np.exp(inputs - np.max(inputs)) \n",
    "    \n",
    "    # Normalize \n",
    "    probabilities = exp_values / np.sum(exp_values)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(imageA, imageB):\n",
    "    return 1 - ssim(imageA, imageB, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_L_dist(adv_map, targ_map):\n",
    "    n = len(adv_map)\n",
    "    l1_dist = np.linalg.norm(adv_map.reshape((n, -1)) - targ_map.reshape((n, -1)), 1, axis=1) \n",
    "    \n",
    "    l1_dist = l1_dist[0]/(32*32)\n",
    "    return l1_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR 10 selected images dataset \n",
    "selected_images_file_path = \"data/1000_cifar10_images_paths_filter65.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading images selected image paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_images_list_file = open(selected_images_file_path, \"r\")\n",
    "loaded_image_paths_list = selected_images_list_file.read()\n",
    "\n",
    "### Converst file content into list using ast\n",
    "loaded_image_paths_list = ast.literal_eval(loaded_image_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_image_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cifar10png/test/airplane/0466.png'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_image_paths_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment3_method(target_classifier, attack, image_list): \n",
    "    column_list = ['image', 'benign_pred', 'benign_conf', 'adv_pred', 'adv_conf', 'attack_time', 'noise_ratio'] \n",
    "    results_df =  pd.DataFrame(columns = column_list) \n",
    "    \n",
    "    for image in image_list: \n",
    "        input_image = Image.open(image)\n",
    "        input_tensor = preprocess(input_image)\n",
    "        input_batch = input_tensor.unsqueeze(0).numpy().astype(np.float32)\n",
    "        \n",
    "        preds = target_classifier.predict(input_batch)  \n",
    "        predicted_label = np.argmax(preds, axis=1)[0] \n",
    "        \n",
    "        confidence = round(np.max(softmax_activation(preds), axis=1)[0], 3) \n",
    "        \n",
    "        ## attack \n",
    "        start = time.time() \n",
    "        adv_image = attack.generate(x=input_batch)\n",
    "        attack_time = time.time()-start \n",
    "        \n",
    "        noise_ratio = compare_images(input_batch[0].transpose(1,2,0), adv_image[0].transpose(1,2,0))\n",
    "        noise_ratio = round(noise_ratio, 5) \n",
    "        \n",
    "        l1_distance = calc_L_dist(adv_image, input_batch)\n",
    "        \n",
    "        adv_prediction = target_classifier.predict(adv_image)  \n",
    "        adv_predicted_label = np.argmax(adv_prediction, axis=1)[0] \n",
    "        adv_confidence = round(np.max(softmax_activation(adv_prediction), axis=1)[0], 3)  \n",
    "        \n",
    "        results_df = results_df.append({'image': image, \n",
    "                                       'benign_pred': predicted_label, \n",
    "                                       'benign_conf': confidence, \n",
    "                                       'adv_pred': adv_predicted_label,\n",
    "                                       'adv_conf': adv_confidence, \n",
    "                                       'attack_time': attack_time, \n",
    "                                       'noise_ratio': noise_ratio, \n",
    "                                       'l1_distance': l1_distance}, ignore_index=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_result(results, total_images):\n",
    "    avg_benign_conf = round(results['benign_conf'].mean(), 3)\n",
    "    benign_conf_std = round(results['benign_conf'].std(), 3)\n",
    "    \n",
    "    attack_success_count = results[results.benign_pred != results.adv_pred][\"image\"].count()\n",
    "    attack_failure_count = total_images - attack_success_count \n",
    "    \n",
    "    avg_adv_success_conf = round(results[results.benign_pred != results.adv_pred][\"adv_conf\"].mean(), 3) \n",
    "    adv_success_conf_std = round(results[results.benign_pred != results.adv_pred][\"adv_conf\"].std(), 3) \n",
    "    \n",
    "    avg_adv_fail_conf = round(results[results.benign_pred == results.adv_pred][\"adv_conf\"].mean(), 3) \n",
    "    adv_fail_conf_std = round(results[results.benign_pred == results.adv_pred][\"adv_conf\"].std(), 3) \n",
    "    \n",
    "    avg_attack_time = round(results['attack_time'].mean(), 4) \n",
    "    attack_time_std = round(results['attack_time'].std(), 4) \n",
    "    \n",
    "    avg_noise_ratio = round(results['noise_ratio'].mean(), 5) \n",
    "    noise_ratio_std = round(results['noise_ratio'].std(), 5)\n",
    "    \n",
    "    avg_l1_distance = round(results['l1_distance'].mean(), 5)      \n",
    "    l1_distance_std = round(results['l1_distance'].std(), 5)  \n",
    "    \n",
    "    \n",
    "    print(\"Benign average confidence: {} ± {}\".format(avg_benign_conf, benign_conf_std))\n",
    "    print(\"Attack success rate: {}/1K ({}±{})\".format(attack_success_count, avg_adv_success_conf, adv_success_conf_std))\n",
    "    print(\"Attack failure rate: {}/1K ({}±{})\".format(attack_failure_count, avg_adv_fail_conf, adv_fail_conf_std))\n",
    "    print(\"Average attack time: {} ± {}\".format(avg_attack_time, attack_time_std))\n",
    "    print(\"Average noise ratio: {} ± {}\".format(avg_noise_ratio, noise_ratio_std))    \n",
    "    print(\"Average l1 distance: {} ± {}\".format(avg_l1_distance, l1_distance_std))  \n",
    "    print(\"===================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded...\n"
     ]
    }
   ],
   "source": [
    "model_resnet18 = ResNet18() \n",
    "model_resnet34 = ResNet34()\n",
    "model_resnet50 = ResNet50()\n",
    "model_resnet101 = ResNet101()\n",
    "model_resnet152 = ResNet152() \n",
    "\n",
    "model_vgg11 = VGG('VGG11')\n",
    "model_vgg13 = VGG('VGG13')\n",
    "model_vgg16 = VGG('VGG16')\n",
    "model_vgg19 = VGG('VGG19')\n",
    "\n",
    "model_densenet121 = DenseNet121() \n",
    "model_densenet161 = DenseNet161() \n",
    "model_densenet169 = DenseNet169() \n",
    "model_densenet201 = DenseNet201() \n",
    "\n",
    "resnet18_file_name = \"trained_models_cifar10/resnet18_cifar10_lr01.pth\"  \n",
    "resnet34_file_name = \"trained_models_cifar10/resnet34_cifar10_lr01.pth\"  \n",
    "resnet50_file_name = \"trained_models_cifar10/resnet50_cifar10_lr01.pth\"  \n",
    "resnet101_file_name = \"trained_models_cifar10/resnet101_cifar10_lr01.pth\"  \n",
    "resnet152_file_name = \"trained_models_cifar10/resnet152_cifar10_lr01.pth\"  \n",
    "\n",
    "vgg11_file_name = \"trained_models_cifar10/vgg11_cifar10_lr01.pth\"  \n",
    "vgg13_file_name = \"trained_models_cifar10/vgg13_cifar10_lr01.pth\"  \n",
    "vgg16_file_name = \"trained_models_cifar10/vgg16_cifar10_lr01.pth\"  \n",
    "vgg19_file_name = \"trained_models_cifar10/vgg19_cifar10_lr01.pth\"  \n",
    "\n",
    "densenet121_file_name = \"trained_models_cifar10/densenet121_cifar10_lr01.pth\"  \n",
    "densenet161_file_name = \"trained_models_cifar10/densenet161_cifar10_lr01.pth\"  \n",
    "densenet169_file_name = \"trained_models_cifar10/densenet169_cifar10_lr01.pth\"  \n",
    "densenet201_file_name = \"trained_models_cifar10/densenet201_cifar10_lr01.pth\"  \n",
    "\n",
    "model_resnet18.load_state_dict(torch.load(resnet18_file_name, map_location=device_name)['net'])\n",
    "model_resnet34.load_state_dict(torch.load(resnet34_file_name, map_location=device_name)['net'])\n",
    "model_resnet50.load_state_dict(torch.load(resnet50_file_name, map_location=device_name)['net'])\n",
    "model_resnet101.load_state_dict(torch.load(resnet101_file_name, map_location=device_name)['net'])\n",
    "model_resnet152.load_state_dict(torch.load(resnet152_file_name, map_location=device_name)['net'])\n",
    "\n",
    "model_vgg11.load_state_dict(torch.load(vgg11_file_name, map_location=device_name)['net'])\n",
    "model_vgg13.load_state_dict(torch.load(vgg13_file_name, map_location=device_name)['net'])\n",
    "model_vgg16.load_state_dict(torch.load(vgg16_file_name, map_location=device_name)['net'])\n",
    "model_vgg19.load_state_dict(torch.load(vgg19_file_name, map_location=device_name)['net'])\n",
    "\n",
    "model_densenet121.load_state_dict(torch.load(densenet121_file_name, map_location=device_name)['net'])\n",
    "model_densenet161.load_state_dict(torch.load(densenet161_file_name, map_location=device_name)['net'])\n",
    "model_densenet169.load_state_dict(torch.load(densenet169_file_name, map_location=device_name)['net'])\n",
    "model_densenet201.load_state_dict(torch.load(densenet201_file_name, map_location=device_name)['net'])\n",
    "\n",
    "model_resnet18.eval()\n",
    "model_resnet34.eval()\n",
    "model_resnet50.eval()\n",
    "model_resnet101.eval()\n",
    "model_resnet152.eval()\n",
    "\n",
    "model_vgg11.eval()\n",
    "model_vgg13.eval()\n",
    "model_vgg16.eval()\n",
    "model_vgg19.eval()\n",
    "\n",
    "model_densenet121.eval()\n",
    "model_densenet161.eval()\n",
    "model_densenet169.eval()\n",
    "model_densenet201.eval()\n",
    "\n",
    "print(\"Loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_models_list = [model_resnet18, model_resnet34, model_resnet50, model_resnet101, model_resnet152, \n",
    "                      model_vgg11, model_vgg13, model_vgg16, model_vgg19,\n",
    "                      model_densenet121, model_densenet161, model_densenet169, model_densenet201]\n",
    "target_models_names = [\"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\",\n",
    "                       \"vgg11\", \"vgg13\", \"vgg16\",  \"vgg19\",  \n",
    "                       \"densenet121\", \"densenet161\", \"densenet169\", \"densenet201\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(target_models_list)): \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Create the ART classifier\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=target_models_list[i],\n",
    "        loss=criterion,\n",
    "        input_shape=(3, 32, 32),\n",
    "        nb_classes=10,\n",
    "        device_type='cuda:2'\n",
    "    )\n",
    "    \n",
    "#     pgd_attack = ProjectedGradientDescent(classifier, max_iter=20, eps_step=1, eps=0.01) \n",
    "#     fgsm_attack = FastGradientMethod(estimator = classifier, eps=0.01)\n",
    "#     newton_attack = NewtonFool(classifier=classifier, max_iter=5, verbose=False) \n",
    "#     attack_simba = SimBA(classifier=classifier, epsilon = 0.05, max_iter=5000)\n",
    "    hopskipjump_attack = HopSkipJump(classifier=classifier, max_iter=20, verbose=False)\n",
    "#     cw_attack = CarliniL2Method(classifier=classifier, max_iter=2, learning_rate=0.05, verbose=False)\n",
    "    result_table = experiment3_method(classifier, hopskipjump_attack, loaded_image_paths_list)      \n",
    "    \n",
    "    result_table.to_csv(\"exp3_results/{}_cifar10_hopskipjump.csv\".format(target_models_names[i]), index=False)\n",
    "    print(\"Target model: {}\".format(target_models_names[i]))\n",
    "    summarize_result(result_table, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
